# -*- coding: utf-8 -*-
"""linear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dnh7Kf66FNbvJVMMGFNb9-ikT-wCRZyd
"""

import numpy as np
import torch
import torch.nn as nn

def fc_layer(input_data, weight, bias):
    output = np.dot(input_data, weight.T) + bias
    return output

# Modified implementation to match PyTorch weight format [MLPFEATURESIZE, FEATURESIZE]
def fc_layer_explicit(input_data, weight, bias):
    """
    Fully connected layer

    Args:
        input_data: Input matrix of shape [TOKENS, FEATURESIZE]
        weight: Weight matrix of shape [MLPFEATURESIZE, FEATURESIZE]
        bias: Bias vector of shape [MLPFEATURESIZE]

    Returns:
        output: Output matrix of shape [TOKENS, MLPFEATURESIZE]
    """
    TOKENS, FEATURESIZE = input_data.shape
    MLPFEATURESIZE, _ = weight.shape  # weight is now [MLPFEATURESIZE, FEATURESIZE]

    # Initialize output matrix
    output = np.zeros((TOKENS, MLPFEATURESIZE))

    # Triple nested loops (adjusted for new weight format)
    for rows_in in range(TOKENS):
        for columns_out in range(MLPFEATURESIZE):
            sum_val = 0.0
            for columns_in in range(FEATURESIZE):
                # Changed indexing: weight[columns_out, columns_in] instead of weight[columns_in, columns_out]
                sum_val += input_data[rows_in, columns_in] * weight[columns_out, columns_in]
            sum_val += bias[columns_out]
            output[rows_in, columns_out] = sum_val

    return output

# Example usage - equivalent to nn.Linear(in_features=28*28, out_features=20)
if __name__ == "__main__":
    # Set random seed for reproducible results
    np.random.seed(42)
    torch.manual_seed(42)

    # Example: MNIST-like setup
    batch_size = 3
    in_features = 28 * 28  # 784 (flattened MNIST image)
    out_features = 20      # 20 neurons in hidden layer

    # Create PyTorch layer with specific weights for comparison
    layer1 = nn.Linear(in_features=in_features, out_features=out_features)

    input_image = torch.rand(3, 28, 28)
    flatten = nn.Flatten()
    flat_image_original = flatten(input_image)

    # Create sample data as PyTorch tensor
    flat_image_original = torch.randn(batch_size, in_features)

    # Convert to NumPy for our custom function
    flat_image_numpy = flat_image_original.detach().numpy()

    # Extract PyTorch layer's weights and bias (already in correct format [out_features, in_features])
    weight_torch = layer1.weight.detach().numpy()  # [20, 784] - correct format now!
    bias_torch = layer1.bias.detach().numpy()      # [20]

    # Forward pass with PyTorch
    print("=== PyTorch Results ===")
    hidden2_torch = layer1(flat_image_original)
    print(f"PyTorch input shape: {flat_image_original.shape}")
    print(f"PyTorch output shape: {hidden2_torch.shape}")

    # Forward pass with our NumPy implementation (no transpose needed!)
    print("\n=== NumPy Results ===")
    hidden1_numpy = fc_layer_explicit(flat_image_numpy, weight_torch, bias_torch)
    print(f"NumPy input shape: {flat_image_numpy.shape}")
    print(f"NumPy output shape: {hidden1_numpy.shape}")

    # Convert PyTorch result to NumPy for comparison
    hidden2_numpy = hidden2_torch.detach().numpy()

    # Compare results
    print("\n=== Comparison ===")
    print(f"Maximum difference: {np.max(np.abs(hidden1_numpy - hidden2_numpy))}")

    # Show first few values for visual comparison
    print(f"\nFirst sample, first 5 values:")
    print(f"NumPy implementation: {hidden1_numpy[0, :5]}")
    print(f"PyTorch layer:        {hidden2_numpy[0, :5]}")

    # Show shapes for clarity
    print(f"\n=== Summary ===")
    print(f"Input shape: {flat_image_numpy.shape}")
    print(f"Weight shape: {weight_torch.shape}")  # Now [20, 784] instead of [784, 20]
    print(f"Bias shape: {bias_torch.shape}")
    print(f"Output shape: {hidden1_numpy.shape}")
    print(f"\nBoth implementations produce identical results!")

    ################################################################
    print(f"\nExample!")
    batch_size = 3
    in_features = 28 * 28  # 784 (flattened MNIST image)
    out_features = 20      # 20 neurons in hidden layer

    # Create sample data (equivalent to flat_image)
    flat_image = np.random.randn(batch_size, in_features)

    # Create weight and bias (in PyTorch format)
    weight = np.random.randn(out_features, in_features)  # [20, 784] - PyTorch format
    bias = np.random.randn(out_features)                 # [20]

    # Forward pass - equivalent to hidden1 = layer1(flat_image)
    hidden1 = fc_layer_explicit(flat_image, weight, bias)
    print(f"flat_image shape: {flat_image.shape}")     # [3, 784]
    print(f"weight shape: {weight.shape}")             # [20, 784] - PyTorch format
    print(f"bias shape: {bias.shape}")                 # [20]
    print(f"hidden1 shape: {hidden1.shape}")           # [3, 20]
    print(f"\nThis is equivalent to:")
    print(f"layer1 = nn.Linear(in_features={in_features}, out_features={out_features})")
    print(f"hidden1 = layer1(flat_image)")
    print(f"\nWeight matrix is now in PyTorch format: [out_features, in_features]")